{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c61cea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/jordanjones/Documents/sherlock'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Attention, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1aa4b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess(data):\n",
    "\n",
    "    import re\n",
    "\n",
    "    def clean_text(document):\n",
    "        document = document.lower() #lower case\n",
    "        document = re.sub('mr.', 'mr', document)\n",
    "        document = re.sub('\\n+', ' ', document ) #Get rid of the string \\n\n",
    "        document = re.sub(\"'\", \"\", document) #Prevent don't becoming don t etc\n",
    "        document = re.sub('[^.\\w\\s+]', ' ', document) #Remove anything that is not digits or letters and then remove whitespace\n",
    "        document = re.sub(r'\\s+', ' ', document) #Reomove all whitepaces\n",
    "        \n",
    "        return document\n",
    "    data = clean_text(data)\n",
    "\n",
    "\n",
    "\n",
    "    sentences = data.split('.')\n",
    "\n",
    "\n",
    "    from nltk.corpus import stopwords\n",
    "    stop = set(stopwords.words(\"english\"))\n",
    "    \n",
    "\n",
    "    #REMOVE STOPWORDS\n",
    "    tokens = data.split()\n",
    "    tokens_filtered = [word for word in tokens if word not in stop] #Take the stopwords out\n",
    "         #FREQUENCY\n",
    "    word_freq = {}\n",
    "    for word in tokens_filtered:\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] =1\n",
    "        else:\n",
    "            word_freq[word] +=1\n",
    "        #GET SENTENCES\n",
    "    \n",
    "    import nltk\n",
    "\n",
    "    sentence_scores = {}\n",
    "        #GET SENTENCE SCORES\n",
    "    for sentence in sentences:\n",
    "        sent_tokens = sentence.split()  # tokens in THIS sentence only\n",
    "        score = 0\n",
    "        for word in sent_tokens:\n",
    "            score += word_freq.get(word, 0)\n",
    "            sentence_scores[sentence] = score\n",
    "\n",
    "\n",
    "    import heapq \n",
    "    selected_sentences = heapq.nlargest(2, sentence_scores, key=sentence_scores.get)\n",
    "    text_summary = ' '.join(selected_sentences)\n",
    "            \n",
    "    return text_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14002c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64973243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you do not add imagination to your other great qualities but if you could for one moment put yourself in the place of this young man would you choose the very night after the will had been made to commit your crime would it not seem dangerous to you to make so very close a relation between the two incidents again would you choose an occasion when you are known to be in the house when a servant has let you in and finally would you take the great pains to conceal the body and yet leave your own stick as a sign that you were the criminal confess lestrade that all this is very unlikely  well now who would have thought it and how deceptive appearances may be to be sure such a nice young man to look at it is a lesson to us not to trust our own judgment is it not lestrade yes some of us are a little too much inclined to be cocksure mr holmes said lestrade\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "series = []\n",
    "\n",
    "for filename in os.listdir(path):#String directory in list\n",
    "    file_path = os.path.join(path, filename) #Path = path + filename\n",
    "\n",
    "    \n",
    "    if os.path.isfile(file_path): \n",
    "        with open(file_path, 'r', encoding='utf-8') as file: \n",
    "                series.append(file.read())#Read each file as string\n",
    "        \n",
    "\n",
    "x = [preprocess(i) for i in series] #Call function on each story\n",
    "print(x[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1e1e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51c0e131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x= x[:56]\n",
    "\n",
    "y=[]\n",
    "\n",
    "y.append('uncovered trevors past remembered fordingham thought beddoes fled concluded desperation drove murder flight terror afterward')\n",
    "y.append('asked fear heard gregson guessed gennaro receive thanks new york opinion advice view answered')\n",
    "y.append('found armchair watched moran bent helen tested surprise old rooms observation careful investigation evening')\n",
    "y.append('remembered intruder saw brunton seemed see woman clutched treasure dashed slab crashing violently quickly frightened')\n",
    "y.append('questioned young man risk crime appearances deceive realized love drove mad fearing brute alone decision')\n",
    "y.append('questioned young man risk crime appearances deceive realized love drove mad fearing brute alone decision')\n",
    "y.append('heard steps voices watched widow saw face noted terror chest belongings carefully inspected closely examined')\n",
    "y.append('smiled said whimsical watched news met garrideb struggled intruding bug hunter continuously observed strange')\n",
    "y.append('heard whistles gipsies clang helen saw shriek stabbed air suddenly warning danger quickly realized imminent')\n",
    "y.append('saw picture could see observed shook head drew chair spread papers carefully documents analyzed thoroughly')\n",
    "y.append('see five think individual walks upstairs hold hand display stone ran off quickly avoid danger')\n",
    "y.append('know turner averse imagine maddening must say clutches saw mccarthy running observed keeper nearby careful')\n",
    "y.append('deduced smell led discovery said expected obtain think cautiously carefully considered investigation plans concluded method')\n",
    "y.append('fancy said might learn found secret prisoner satisfaction opened eyes knew drawn back safe')\n",
    "y.append('put could would choose take confess unlikely begged fell began examine decide finally took decisive action')\n",
    "y.append('took bottle syringe clapped eyes merchant had treasure observed clear enough lamp illuminated carefully')\n",
    "y.append('mass think said want talk affair perkins hard douglas sorry future stake shrugged shoulders concern')\n",
    "y.append('john mason left set work careful examination graves ranging ancient saxon norman hugos odos reached falder')\n",
    "y.append('suppose son came bed risk dressing room opened bureau took coronet broke portion concealed gems returned')\n",
    "y.append('lie number one said old man never saw africa pipe smoke begin think warning cautious')\n",
    "y.append('always opinion publish singular facts dispel rumours agitated university societies received letter student prague observed professor')\n",
    "y.append('suppose cadogan west wished make way building hours need three keys reach papers clerk sell copy')\n",
    "y.append('likely gone paris morrow good gentleman showed clearly kindly wrong frank right putting secret square quiet observed')\n",
    "y.append('ask fear law judge condemn gennaro done gregson american official new york husband vote thanks guarded safe')\n",
    "y.append('evening james bicycled confessed told arthur met wood mother longed see awaiting moor come midnight find horse')\n",
    "y.append('gentleman fear law judge condemn gennaro done gregson american official new york husband vote thanks guarded safe killed')\n",
    "y.append('oh come man look faces cried offer reward officials agree sum cannot done promptly drew attention assailant')\n",
    "y.append('mass saw sister law observe line boats call belfast dublin waterford browner committed deed embarked steamer post packet')\n",
    "y.append('indiscreet letter marriage love happiness lives stake dilemma politics trust fear husband sorrow lucas death')\n",
    "y.append('violence class war noisy weapon credibility union secrecy terror family law failure witnesses funds')\n",
    "y.append('man sat street paper face grief horror pinner request manager pycroft enter office impression employers practice work furniture')\n",
    "y.append('met called home safe walked father returned hosmer angel duties hunting crop steps door windibank france foreman learned')\n",
    "y.append('rare flower grew root woman brain heart looked face freshness coloring oddity black eyes temper path escape village fulworth')\n",
    "y.append('met rucastle keys face changed jovial telegram night holmes chemical research retort test tube salary alice rights office ledgers')\n",
    "y.append('heard anxious intruder bedroom joseph concealed turned suspicions attempt nurse absent acquainted house threat naval treaty phelps screamed')\n",
    "y.append('lestrade consulting expert concluded incidents lunacy crime traced windings case grotesque attempt busts chiswick workmanlike')\n",
    "y.append('popular tenors criminal weapon reed beds carry wardrobe obstacle wife dislike intellectual puzzle flower root atmosphere woman heart path')\n",
    "y.append('soames papers room case shape save speak dead father understand profit deed gilchrist honourable young man horror reproach')\n",
    "y.append('begged prayed mercy laughed coward heart lips twitching face revolver bludgeons tortures nerves money lantern intellectual face eyes glasses')\n",
    "y.append('beg goodness sit boxes interfere merryweather crate injured face knees floor lantern magnifying cracks red hair pawnbroker manufactory paper')\n",
    "y.append('telegram sender overton trinity enormous man stone bone muscle shoulders comely face anxiety money relative bearded danger inquiry')\n",
    "y.append('merryweather crate injured expression knees floor lantern magnifying examine cracks sneer hunting crop windibank tallow candle hat upstairs')\n",
    "y.append('burglars early hour murder plunder bottle lied covering criminal thoughts dining room investigation lady brackenstall tried woman')\n",
    "y.append('lady dining room questions silent drive eager figure unsolved problem restless mind wife street horror astonishment')\n",
    "y.append('wisteria lodge john scott eccles bleak windy march foreigners events death explanation note hypothesis')\n",
    "y.append('boxes solemn perched crate injured expression knees floor lantern magnifying lens examine minutely cracks stones')\n",
    "y.append('deposit comparatively small link larger grounds neighbours secret jealously hydraulic engineers inquiry fields plans experience')\n",
    "y.append('gods sake think intellectual puzzle life death wife murderer child danger blood exposed neck vampires')\n",
    "y.append('two men empty house cabman poison blood murderer ring rache capture dying useful life energy reaction foreseen feet')\n",
    "y.append('horse stable key opium stranger paper maid wound knife pullman dartmoor training stables curry incised brain injury probable')\n",
    "y.append('lady picked steps carefully track path soft bed cool hand episode yoxley place death crime')\n",
    "y.append('rocket tossed crowd shriek smoke ostlers servant maids lady level master attention keen powers')\n",
    "y.append('danger memory murderer risks glance window crouching spring blow assassin amazement convulsed face sardonic voice')\n",
    "y.append('infection respect judgment pulse temperature deceive sigh box post fainting shaking hiding evil carelessness dissimulation secret presence scheme')\n",
    "y.append('recommend return hand case want desire encourage false hopes assure safety lady frances photograph lid')\n",
    "y.append('convinced mortimer tregennis murderer money family insane devils foot powder killed sister brenda remorse fate')\n",
    "\n",
    "\n",
    "print(len(y))\n",
    "print(len(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44edcea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sos uncovered trevors past remembered fordingham thought beddoes fled concluded desperation drove murder flight terror afterward eos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = ['sos ' + sentence.strip() + ' eos' for sentence in y] #Sequence boundries\n",
    "\n",
    "print(y[0])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47d82d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43, 58, 952, 81, 21, 1, 953, 44, 372, 954, 1, 77, 2, 54, 955, 8, 1, 956, 5, 957, 1, 268, 373, 1, 958, 47, 4, 269, 114, 81, 3, 115, 6, 63, 14, 4, 23, 35, 1, 149, 55, 959, 3, 60, 20, 960, 1, 270, 150, 82, 92, 93, 7, 17, 87, 151, 174, 31, 24, 271, 45, 11, 29, 43, 209, 22, 961, 61, 44, 537, 374, 2, 1, 962, 37, 7, 375, 51, 100, 6, 10, 13, 26, 963, 38, 210, 3, 538, 272], [5, 101, 175, 7, 13, 176, 9, 273, 43, 17, 177, 3, 116, 40, 1, 136, 94, 273, 152, 274, 21, 376, 13, 275, 24, 137, 32, 46, 15, 67, 102, 42, 20, 153, 31, 1, 211, 539, 373, 35, 1, 212, 7, 103, 117, 46, 38, 540, 276, 2, 268, 83, 26, 34, 7, 541, 6, 8, 154, 213, 36, 542, 214, 138, 277, 4, 377, 543, 278, 2, 215, 24, 378, 279, 13, 17, 104, 6, 10, 28, 17, 68, 3, 36, 279, 13, 17, 544, 10, 7, 379, 3, 26, 280, 32, 1, 281, 545, 39, 380, 5, 546, 53, 1, 547, 58, 548, 118, 32, 549, 7, 13, 17, 4, 381, 281, 35, 4, 155, 5, 8, 36, 119, 7, 88, 4, 550, 2, 24, 216, 8, 136, 551], [48, 10, 14, 24, 382, 100, 6, 35, 56, 964, 3, 156, 7, 139, 217, 8, 24, 105, 965, 383, 8, 24, 95, 105, 84, 5, 106, 966, 6, 7, 28, 17, 178, 24, 105, 271, 100, 8, 1, 64, 383, 37, 15, 67, 48, 380, 967, 34, 22, 28, 27, 120, 21, 16, 968, 384, 121, 25, 69, 969, 970, 971, 94, 21, 1, 972, 973, 974, 5, 1, 975, 282, 552, 976, 385, 977, 978, 979, 107, 980], [1, 386, 2, 45, 11, 82, 92, 93, 108, 2, 140, 283, 284, 1, 387, 41, 1, 388, 389, 218, 1, 270, 150, 1, 390, 391, 1, 392, 393, 1, 394, 23, 1, 285, 286, 1, 287, 288, 1, 289, 290, 1, 395, 179, 283, 284, 7, 396, 553, 100, 6, 7, 219, 17, 3, 554, 31, 11, 29, 43, 209, 122, 981, 3, 70, 982, 22, 220, 47, 7, 157, 6, 87, 22, 33, 57, 48, 397, 3, 555, 109, 1, 398, 8, 37, 71, 22, 34, 221, 28, 17, 158, 177, 9, 159, 54, 8, 38, 399, 78, 9, 33, 400, 221, 81, 47, 9, 556, 25, 1, 291, 24, 292, 62, 293, 3, 557, 401, 29, 1, 222, 14, 110, 44, 1, 123, 61, 21, 37, 1, 402, 14, 403, 558, 6, 1, 294, 14, 42, 404, 25, 1, 559, 2, 1, 72], [9, 65, 27, 295, 296, 3, 38, 64, 89, 297, 34, 53, 9, 28, 32, 22, 223, 160, 224, 8, 1, 90, 2, 36, 91, 23, 13, 9, 124, 1, 39, 61, 125, 1, 138, 33, 57, 110, 3, 225, 38, 85, 13, 10, 27, 298, 299, 3, 9, 3, 126, 48, 39, 226, 4, 300, 180, 1, 56, 181, 161, 13, 9, 124, 49, 301, 47, 9, 73, 182, 3, 26, 8, 1, 72, 47, 4, 227, 67, 228, 9, 8, 5, 162, 13, 9, 86, 1, 89, 302, 3, 303, 1, 304, 5, 183, 163, 38, 95, 305, 29, 4, 164, 6, 9, 58, 1, 165, 184, 96, 6, 62, 36, 30, 39, 229, 42, 101, 55, 13, 17, 104, 10, 5, 78, 560, 306, 83, 26, 3, 26, 307, 79, 4, 561, 91, 23, 3, 120, 35, 10, 30, 4, 562, 3, 54, 27, 3, 308, 70, 95, 309, 30, 10, 27, 96, 185, 87, 2, 54, 73, 4, 127, 186, 166, 563, 3, 26, 405, 20, 11, 31, 96], [9, 65, 27, 295, 296, 3, 38, 64, 89, 297, 34, 53, 9, 28, 32, 22, 223, 160, 224, 8, 1, 90, 2, 36, 91, 23, 13, 9, 124, 1, 39, 61, 125, 1, 138, 33, 57, 110, 3, 225, 38, 85, 13, 10, 27, 298, 299, 3, 9, 3, 126, 48, 39, 226, 4, 300, 180, 1, 56, 181, 161, 13, 9, 124, 49, 301, 47, 9, 73, 182, 3, 26, 8, 1, 72, 47, 4, 227, 67, 228, 9, 8, 5, 162, 13, 9, 86, 1, 89, 302, 3, 303, 1, 304, 5, 183, 163, 38, 95, 305, 29, 4, 164, 6, 9, 58, 1, 165, 184, 96, 6, 62, 36, 30, 39, 229, 42, 101, 55, 13, 17, 104, 10, 5, 78, 560, 306, 83, 26, 3, 26, 307, 79, 4, 561, 91, 23, 3, 120, 35, 10, 30, 4, 562, 3, 54, 27, 3, 308, 70, 95, 309, 30, 10, 27, 96, 185, 87, 2, 54, 73, 4, 127, 186, 166, 563, 3, 26, 405, 20, 11, 31, 96], [35, 123, 1, 128, 2, 4, 564, 983, 984, 94, 1, 985, 2, 565, 40, 1, 566, 986, 70, 987, 34, 22, 74, 22, 230, 988, 989, 567, 5, 49, 990, 991, 310, 21, 54, 141, 32, 1, 992, 2, 1, 993, 994, 37, 159, 54, 2, 1, 995, 2, 1, 61, 5, 32, 1, 996, 5, 997, 2, 4, 998, 999, 568, 569, 1, 1000, 37, 1001, 54, 8, 1002, 1003, 406, 54, 123, 3, 1, 72, 407, 15, 1004, 54, 3, 4, 570, 1005, 1006, 187, 1, 571, 2, 1, 572, 23, 408, 1007, 5, 282, 552, 41, 25, 1, 1008, 120, 2, 231, 8, 1, 1009, 2, 75, 142, 1010, 121, 159, 2, 1, 409, 2, 1011, 5, 1012, 1013, 37, 76, 33, 1014], [42, 100, 31, 11, 25, 4, 573, 7, 31, 10, 14, 410, 574, 143, 7, 27, 7, 59, 17, 104, 144, 6, 38, 1015, 119, 14, 3, 1016, 8, 1, 1017, 1018, 2, 1, 151, 9, 232, 52, 3, 60, 50, 46, 65, 9, 115, 20, 11, 103, 9, 51, 10, 13, 26, 1019, 174, 396, 7, 4, 1020, 211, 25, 4, 575, 1021], [47, 9, 1022, 1, 1023, 2, 576, 35, 61, 1, 411, 2, 4, 188, 2, 577, 55, 73, 44, 1024, 1025, 25, 36, 105, 291, 1, 578, 6, 43, 17, 579, 580, 3, 1026, 6, 1, 291, 67, 49, 1027, 8, 1028, 16, 1029, 311, 1, 189, 1030, 3, 4, 188, 5, 162, 1, 578, 6, 581, 312, 1031, 157, 4, 1032, 582, 37, 97, 17, 57, 1033, 74, 22, 2, 190, 1034, 1035, 6, 1036, 1, 1037, 568, 118, 109, 412, 90, 7, 51, 6, 63, 30, 313, 1038, 3, 51, 6, 1, 191, 83, 26, 1039, 1040, 190, 1041, 35, 123, 7, 104, 6, 76, 33, 27, 1042, 52, 34, 29, 7, 583, 272, 75, 76, 584, 1043, 81, 8, 4, 585, 37, 7, 219, 111, 1044, 233, 24, 378, 312, 10, 14, 1, 188, 1, 413, 188, 63, 14, 586, 314, 37, 76, 13, 1045, 17, 31, 5, 76, 587, 25, 75, 1046, 109, 1, 315, 8, 1, 1047, 2, 1, 1048, 84, 34, 4, 1049, 1050, 1051, 75, 5, 1052, 75, 588], [1, 154, 1053, 14, 8, 36, 1054, 414, 414, 2, 234, 415, 112, 1055, 235, 52, 31, 11, 5, 7, 28, 60, 74, 16, 121, 6, 15, 14, 166, 1056, 14, 36, 4, 416, 1057, 3, 1, 123, 94, 143, 10, 1058, 3, 26, 1059, 1060, 10, 14, 44, 4, 316, 1061, 2, 1, 149, 34, 36, 30, 1062, 20, 11, 167, 59, 15, 68, 1063, 9, 17, 417, 50, 13, 27, 79, 4, 418, 410, 1064, 16, 292, 5, 1065, 50, 3, 1066, 7, 51, 7, 17, 182, 78, 3, 1067, 1, 145, 31, 45, 11], [34, 78, 44, 376, 65, 9, 1068, 6, 1, 589, 30, 27, 590, 44, 8, 16, 72, 22, 419, 420, 94, 421, 56, 97, 68, 74, 1069, 34, 47, 7, 60, 71, 591, 146, 234, 7, 51, 6, 63, 129, 26, 127, 1070, 6, 1, 422, 98, 26, 1071, 109, 1072, 1073, 25, 1074, 419, 423, 424, 35, 61, 1075, 25, 16, 592, 8, 22, 147, 5, 4, 1076, 593, 8, 1, 64, 42, 317, 65, 9, 236, 6, 36, 64, 22, 594, 318, 33, 177, 3, 65, 25, 1, 237, 10, 30, 7, 51, 166, 113, 425, 6, 594, 318, 30, 49, 1077, 1078, 23, 55, 33, 71, 426, 6, 1, 1079, 37, 15, 14, 1080, 14, 2, 1081, 113, 1082, 146, 53, 10, 58, 110, 2, 595, 1083], [375, 1084, 10, 27, 596, 9, 29, 4, 127, 192, 6, 36, 597, 55, 1085, 3, 17, 33, 127, 2, 16, 95, 5, 3, 17, 57, 598, 79, 1086, 3, 427, 59, 428, 319, 2, 1087, 16, 238, 3, 1088, 1089, 55, 30, 1090, 1091, 3, 1, 1092, 5, 6, 8, 79, 4, 39, 405, 1093, 29, 53, 10, 58, 1094, 4, 66, 2, 4, 1095, 5, 62, 314, 13, 1096, 10, 30, 1, 113, 239, 168, 43, 117, 6, 427, 169, 14, 599, 3, 1, 426, 22, 30, 6, 1, 572, 23, 33, 49, 1097, 25, 600, 35, 1, 1098, 5, 6, 1, 600, 28, 27, 17, 57, 16, 238, 32, 16, 238, 14, 567, 5, 15, 143, 27, 117, 47, 15, 13, 240], [7, 1099, 429, 15, 31, 6, 48, 1100, 49, 422, 29, 217, 401, 125, 24, 430, 1101, 1102, 28, 601, 1, 431, 432, 2, 48, 1103, 4, 23, 29, 20, 45, 11, 10, 602, 1104, 1, 433, 1105, 74, 37, 1106, 1107, 603, 40, 1, 434, 2, 1108, 6, 87, 64, 434, 6, 2, 589, 32, 604, 97, 26, 158, 1, 605, 241, 6, 1, 435, 84, 97, 320, 26, 1, 148, 1109, 5, 1, 1110, 436, 37, 406, 3, 1, 606, 2, 1, 1111, 8, 4, 1112, 42, 1113, 158, 74, 4, 1114, 1115, 59, 607, 8, 1, 1116, 2, 85, 29, 4, 1117, 604, 2, 1, 1118, 2, 70, 1119, 1120], [11, 321, 30, 7, 322, 2, 4, 316, 119, 2, 1121, 5, 1122, 3, 36, 156, 6, 53, 22, 28, 242, 1, 1123, 437, 22, 97, 438, 78, 1, 1124, 2, 1125, 5, 75, 1126, 114, 3, 26, 1127, 4, 287, 271, 33, 68, 3, 60, 50, 21, 439, 15, 31, 5, 29, 15, 28, 440, 608, 34, 16, 95, 1128, 1, 1129, 2, 49, 288, 58, 1130], [1, 431, 45, 11, 82, 92, 93, 108, 2, 140, 4, 323, 8, 324, 1, 164, 2, 1, 325, 1, 609, 2, 45, 11, 4, 610, 8, 611, 1, 142, 326, 441, 4, 66, 2, 612, 1, 613, 327, 191, 1, 234, 614, 615, 1, 23, 25, 1, 616, 617, 1, 12, 2, 1, 384, 618, 1, 12, 2, 1, 413, 188, 1, 12, 2, 1, 442, 443, 1, 12, 2, 1, 619, 620, 1, 12, 2, 1, 621, 328, 1, 12, 2, 1, 622, 623, 1, 386, 2, 45, 11, 283, 284, 1, 387, 41, 1, 388, 389, 218, 1, 270, 150, 1, 390, 391, 1, 392, 393, 1, 394, 23, 1, 285, 286, 1, 287, 288, 1, 289, 290, 1, 395, 179, 1, 240, 2, 45, 11, 1, 12, 2, 1, 243, 72, 1, 12, 2, 1, 624, 625, 1, 12, 2, 1, 415, 112, 1, 12, 2, 1, 626, 627, 1, 12, 2, 1, 628, 629, 1, 12, 2, 329, 630, 1, 12, 2, 631, 632, 633, 1, 12, 2, 1, 444, 634, 1, 12, 2, 1, 77, 445, 1, 12, 2, 1, 635, 636, 637, 1, 12, 2, 1, 446, 77, 330, 1, 12, 2, 1, 638, 639, 1, 12, 2, 1, 331, 420, 1, 640, 2, 1, 641, 1, 327, 2, 116, 16, 130, 332, 244, 1, 12, 2, 245, 193, 1, 12, 2, 1, 642, 333, 1, 12, 2, 1, 142, 643, 1, 12, 2, 1, 644, 645, 170, 1, 12, 2, 1, 189, 646, 1, 447, 2, 80, 334, 448, 1, 12, 2, 1, 335, 336, 16, 130, 332, 1, 66, 647, 2, 45, 11, 244, 1, 648, 246, 1, 649, 650, 1, 12, 2, 1, 651, 247, 1, 12, 2, 1, 77, 652, 1, 12, 2, 1, 653, 654, 1, 12, 2, 1, 77, 655, 1, 179, 2, 656, 657, 1, 12, 2, 1, 449, 23, 1, 12, 2, 1, 658, 659, 1, 12, 2, 1, 660, 450, 1, 12, 2, 661, 105, 90, 1, 12, 2, 1, 662, 663, 4, 323, 8, 324, 108, 2, 140, 171, 7, 20, 45, 11, 1, 337, 2, 241, 1, 664, 372, 191, 46, 99, 665, 33, 3, 235, 70, 666, 667, 4, 668, 669, 153, 670, 46, 15, 129, 65, 671, 8, 1, 672, 171, 673, 44, 1, 89, 674, 338, 1, 248, 2, 675, 99, 676, 677, 25, 1, 678, 4, 451, 32, 131, 1, 679, 680, 4, 681, 2, 1, 682, 2, 99, 100, 683, 9, 65, 27, 295, 296, 3, 38, 64, 89, 297, 34, 53, 9, 28, 32, 22, 223, 160, 224, 8, 1, 90, 2, 36, 91, 23, 13, 9, 124, 1, 39, 61, 125, 1, 138, 33, 57, 110, 3, 225, 38, 85, 13, 10, 27, 298, 299, 3, 9, 3, 126, 48, 39, 226, 4, 300, 180, 1, 56, 181, 161, 13, 9, 124, 49, 301, 47, 9, 73, 182, 3, 26, 8, 1, 72, 47, 4, 227, 67, 228, 9, 8, 5, 162, 13, 9, 86, 1, 89, 302, 3, 303, 1, 304, 5, 183, 163, 38, 95, 305, 29, 4, 164, 6, 9, 58, 1, 165, 184, 96, 6, 62, 36, 30, 39, 229], [1, 1131, 249, 1, 684, 1132, 139, 1133, 685, 1134, 1, 239, 1135, 35, 1136, 1137, 148, 1, 1138, 2, 1, 249, 1139, 686, 74, 1, 339, 2, 1, 1140, 1, 39, 192, 1141, 3, 1, 85, 1, 1142, 1, 433, 1143, 1, 588, 21, 1, 687, 1144, 25, 190, 21, 1145, 685, 1146, 174, 14, 452, 4, 1147, 8, 37, 4, 23, 591, 1148, 1149, 146, 24, 688, 450, 97, 42, 1150, 2, 250, 1151, 1, 1152, 1, 164, 2, 1, 325, 82, 92, 93, 108, 2, 140, 1, 337, 2, 241, 1, 1153, 2, 1, 66, 8, 689, 2, 4, 690, 1, 340, 2, 1, 1154, 326, 23, 1, 1155, 2, 1156, 193, 45, 11, 1157, 4, 1158, 1, 691, 2, 1, 1159, 1, 318, 251, 1160, 4, 692, 8, 1, 1161, 1, 693, 2, 1, 1162, 1, 89, 1163, 249, 1, 239, 340, 2, 1164, 341, 694, 7, 1, 337, 2, 241, 45, 11, 132, 16, 342, 40, 1, 695, 2, 1, 696, 5, 16, 1165, 697, 40, 412, 1166, 1167, 66], [42, 453, 11, 7, 102, 454, 51, 272, 46, 9, 31, 5, 7, 103, 232, 71, 113, 319, 455, 6, 698, 2, 453, 699, 700, 6, 453, 11, 456, 44, 1168, 31, 11], [65, 9, 252, 6, 15, 13, 701, 3, 141, 52, 42, 144, 1169, 31, 11, 1170, 36, 237, 98, 2, 702, 26, 1171, 3, 1, 1172, 47, 99, 703, 33, 704, 54, 11, 705, 3, 343, 1173, 4, 39, 344, 706, 2, 1, 707, 708, 40, 4, 39, 709, 22, 37, 1174, 3, 26, 710, 8, 1, 1175, 457, 4, 1176, 458, 2, 711, 712, 5, 713, 459, 43, 460, 1, 144, 1177, 5, 144, 1178, 714, 2, 1, 1179, 1180], [7, 51, 6, 53, 1181, 28, 17, 715, 50, 109, 1, 461, 194, 10, 13, 17, 57, 76, 5, 6, 16, 311, 97, 17, 293, 16, 381, 131, 34, 101, 1182, 10, 30, 186, 716, 1183, 186, 716, 101, 20, 11, 9, 117, 1, 717, 55, 607, 598, 24, 1184, 5, 7, 219, 1185, 25, 24, 1186, 340, 9, 252, 6, 38, 238, 114, 122, 40, 16, 345, 718, 35, 89, 346, 3, 38, 719, 84, 462, 38, 720, 132, 81, 38, 328, 721, 347, 74, 1187, 722, 4, 341, 723, 2, 10, 718, 347, 3, 87, 64, 90, 158, 77, 724, 81, 2, 1, 725, 1188, 25, 79, 1189, 6, 726, 129, 242, 133, 5, 317, 463, 25, 1, 64, 725, 444, 109, 1, 84, 8, 37, 15, 464, 169, 3, 1, 727, 107, 2, 465, 1190], [728, 729, 22, 31, 1, 105, 23, 7, 111, 88, 537, 2, 133, 459, 56, 1191, 466, 5, 7, 17, 111, 57, 8, 467, 8, 24, 131, 48, 9, 129, 160, 6, 8, 38, 730, 5, 468, 10, 20, 1192, 11, 46, 15, 731, 30, 732, 31, 1193, 7, 733, 3, 51, 48, 20, 11, 34, 47, 7, 104, 2, 62, 1, 1194, 7, 33, 1195, 3, 1196, 36, 437, 32, 7, 469, 75, 20, 11, 5, 10, 30, 1, 106, 155, 6, 250, 7, 253, 46, 254, 14, 10, 734, 195, 52, 470, 3, 51, 6, 76, 14, 8, 1, 735, 2, 1, 727, 471, 5, 1197, 8, 1198, 467, 4, 23, 408, 736, 30, 4, 1199, 231, 40, 1200, 3, 1201], [1, 12, 2, 1, 449, 23, 82, 92, 93, 20, 45, 11, 14, 348, 2, 349, 6, 7, 59, 737, 1, 192, 472, 1202, 25, 473, 738, 53, 106, 3, 739, 474, 32, 62, 1, 1203, 740, 37, 87, 1204, 409, 466, 741, 1, 742, 5, 58, 1205, 8, 1, 743, 744, 2, 475, 10, 1206, 321, 6, 70, 246, 174, 20, 1207, 476, 4, 145, 40, 4, 688, 745, 8, 746, 55, 31, 6, 15, 14, 1208, 3, 17, 178, 473, 738, 63, 1209, 15, 33, 27, 57, 747, 3, 319, 3, 50], [55, 73, 230, 56, 112, 20, 1210, 5, 167, 65, 172, 1211, 3, 1212, 9, 42, 42, 31, 1, 285, 286, 8, 4, 1213, 477, 2, 702, 10, 30, 748, 3, 115, 6, 1, 77, 112, 749, 750, 1, 478, 37, 172, 143, 44, 1214, 1, 1215, 23, 123, 1, 1216, 23, 331, 5, 1, 1217, 23, 8, 1, 1218, 24, 382, 11, 7, 1219], [233, 68, 101, 20, 11, 31, 15, 35, 130, 1220, 307, 9, 103, 375, 751, 3, 1221, 23, 120, 35, 69, 752, 753, 11, 1222, 8, 1, 123, 90, 31, 11, 7, 59, 479, 9, 3, 754, 4, 755, 756, 40, 224, 32, 1, 757, 83, 86, 4, 127, 155, 196, 172, 13, 758, 21, 1, 759, 5, 230, 1223, 350, 26, 102, 186, 760], [6, 197, 351, 761, 272, 7, 396, 1224, 9, 46, 15, 67, 169, 762, 3, 52, 5, 15, 159, 82, 198, 15, 134, 8, 1, 480, 6, 16, 763, 764, 3, 60, 50, 6, 76, 14, 765, 50, 44, 1, 766, 5, 6, 53, 15, 13, 68, 118, 109, 1, 480, 35, 767, 15, 13, 242, 4, 23, 25, 4, 199, 55, 13, 86, 50, 3, 75, 233, 20, 11, 9, 98, 141, 50, 9, 98, 141, 50, 7, 235, 9, 6, 9, 98, 141, 50, 1, 1225, 33, 1226, 1, 130, 222, 35, 1227, 1228, 5, 14, 1229, 1, 84, 25, 4, 768, 41, 5, 25, 16, 1230, 769, 1231, 8, 1, 315], [24, 378, 279, 13, 17, 104, 6, 10, 28, 17, 68, 3, 36, 279, 13, 17, 544, 10, 7, 379, 3, 26, 280, 32, 1, 281, 545, 39, 380, 5, 546, 53, 1, 547, 58, 548, 118, 32, 549, 7, 13, 17, 4, 381, 281, 35, 4, 155, 5, 8, 36, 119, 7, 88, 4, 550, 2, 24, 216, 8, 136, 551, 9, 138, 770, 6, 36, 458, 2, 771, 352, 35, 481, 772, 5, 773, 48, 6, 1232, 6, 774, 33, 775, 1, 353, 5, 33, 776, 35, 474, 21, 16, 777, 1, 83, 156, 481, 13, 26, 1, 123, 90, 35, 37, 15, 28, 482, 16, 778, 779], [252, 6, 780, 781, 354, 3, 126, 16, 119, 109, 1, 782, 125, 483, 15, 13, 783, 77, 355, 13, 15, 27, 196, 1, 28, 484, 1, 151, 185, 15, 13, 22, 64, 276, 53, 4, 218, 8, 36, 356, 1233, 3, 784, 1, 170, 13, 10, 27, 26, 1234, 3, 485, 1, 170, 32, 169, 146, 3, 86, 1, 1235, 29, 14, 1236, 102, 10, 13, 86, 1237, 1238, 1239, 3, 485, 1, 170, 8, 49, 1240, 119], [1241, 1242, 785, 14, 4, 39, 786, 22, 71, 22, 465, 1243, 141, 1, 173, 2, 1, 1244, 20, 1245, 1246, 1, 1247, 2, 1248, 787, 1249, 787, 1250, 5, 80, 1251, 1252, 10, 30, 425, 6, 43, 59, 17, 454, 44, 3, 788, 3, 789, 106, 6, 36, 313, 175, 20, 11, 114, 790, 3, 54, 36, 197, 791, 78, 15, 139, 54, 30, 113, 146, 7, 129, 51, 5, 15, 486, 54, 39, 792, 5, 793, 6, 7, 14, 487, 5, 6, 794, 14, 461, 5, 6, 43, 59, 26, 795, 488, 8, 1, 487, 53, 43, 58, 48, 255], [5, 101, 175, 7, 13, 176, 9, 273, 43, 17, 177, 3, 116, 40, 1, 136, 94, 273, 152, 274, 21, 376, 13, 275, 24, 137, 32, 46, 15, 67, 102, 42, 20, 153, 31, 1, 211, 539, 373, 35, 1, 212, 7, 103, 117, 46, 38, 540, 276, 2, 268, 83, 26, 34, 7, 541, 6, 8, 154, 213, 36, 542, 214, 138, 277, 4, 377, 543, 278, 2, 215, 101, 7, 60, 10, 24, 137, 24, 1253, 1254, 137, 55, 67, 489, 52, 200, 40, 62, 1255, 15, 143, 10, 25, 16, 95, 435, 147, 15, 357, 1, 1256, 233, 137, 78, 575, 9, 73, 46, 187, 28, 579, 26, 1257, 2, 79, 4, 23, 42, 20], [796, 52, 20, 11, 24, 490, 16, 490, 70, 39, 491, 73, 35, 492, 797, 1258, 1, 155, 1259, 798, 10, 14, 4, 145, 2, 1260, 20, 11, 49, 799, 145, 1261, 196, 24, 311, 4, 1262, 145, 4, 145, 2, 49, 1263, 1264, 437, 7, 28, 27, 20, 11, 7, 28, 27, 44, 1, 22, 374, 201, 1265, 1266, 44, 1, 64, 778, 29, 10, 201, 3, 86, 24, 1267, 202, 428, 8, 4, 237, 2, 800, 7, 28, 27, 493, 1, 1268, 210, 8, 4, 237, 2, 254, 5, 308, 172, 58, 106, 186, 494, 3, 52], [14, 10, 85, 130, 61, 47, 4, 23, 105, 801, 3, 26, 38, 173, 14, 1269, 1270, 1, 203, 1271, 40, 16, 802, 1272, 14, 6, 85, 94, 46, 314, 13, 9, 352, 10, 63, 73, 87, 13, 115, 10, 14, 495, 31, 1273, 4, 495, 2, 56, 1274, 25, 62, 8, 48, 6, 803, 1275, 29, 1276, 10, 28, 7, 1277, 1278, 25, 1, 256, 2, 10, 5, 183, 7, 33, 3, 456, 4, 605, 5, 804, 41, 32, 42, 7, 253, 6, 53, 7, 143, 27, 10, 13, 26, 81, 2, 24, 72, 6, 172, 13, 68, 805, 25, 69, 1279, 769, 5, 10, 13, 26, 24, 127, 1280, 6, 13, 26, 806, 32, 16, 173], [6, 276, 30, 1, 418, 110, 74, 807, 6, 9, 59, 27, 1281, 38, 90, 34, 59, 163, 1, 808, 2, 36, 1282, 439, 8, 1, 1283, 1284, 6, 4, 20, 496, 809, 198, 15, 33, 111, 178, 14, 455, 3, 810, 1, 356, 21, 1, 811, 220, 35, 1, 1285, 108, 209, 1, 23, 198, 43, 33, 178, 8, 1, 251, 25, 16, 197, 202, 812, 81, 8, 813, 2, 50, 5, 29, 15, 257, 358, 35, 54, 10, 201, 3, 52, 6, 7, 33, 111, 257, 21, 4, 41, 37, 1286, 79, 1287, 2, 497, 5, 2, 586, 1288, 497, 2, 4, 256, 79, 29, 1289, 3, 564, 112, 8, 4, 1290], [7, 134, 50, 6, 61, 5, 15, 498, 805, 156, 3, 176, 53, 43, 33, 700, 280, 62, 200, 5, 125, 6, 43, 134, 50, 6, 30, 3, 115, 20, 11, 7, 134, 50, 1291, 32, 423, 34, 125, 6, 173, 114, 118, 161, 5, 20, 814, 815, 28, 27, 68, 3, 1, 72, 152, 113, 74, 816, 15, 817, 818, 358, 35, 1, 819, 2, 1, 820, 499, 21, 1, 821, 41, 10, 30, 27, 171, 2, 24, 500, 3, 24, 246, 34, 822, 4, 359, 360, 823, 5, 7, 51, 7, 219, 501, 824, 217, 3, 15, 132, 56, 825, 128, 3, 1, 826, 34, 196, 15, 28, 827, 10, 63, 14, 4, 828, 829, 2, 128, 21, 1, 478, 1, 430, 496, 149, 830, 5, 40, 1, 502, 43, 28, 60, 20, 351, 361, 503, 35, 1, 831, 2, 16, 832, 122, 1, 833], [55, 28, 17, 1292, 6, 48, 834, 4, 248, 13, 1293, 40, 79, 4, 504, 5, 8, 79, 49, 835, 1294, 17, 1295, 57, 49, 1296, 3, 52, 32, 24, 505, 67, 348, 1297, 24, 258, 34, 7, 28, 27, 120, 21, 75, 1298, 494, 1299, 41, 25, 62, 1, 506, 836, 2, 1, 1300, 8, 75, 1301, 1302, 385, 1303, 6, 71, 91, 23, 13, 1304, 75, 194, 1305, 15, 14, 257, 21, 29, 49, 837, 74, 1, 445, 5, 13, 17, 57, 69, 838, 34, 63, 14, 87, 239, 1306, 203, 8, 1, 23, 37, 486, 1307, 27, 106, 8, 16, 1308, 329, 121, 5, 1309, 41, 34, 320, 8, 1310, 1311, 2, 839, 37, 28, 106, 26, 1312, 29, 1313], [22, 156, 321, 29, 7, 750, 1, 1314, 7, 134, 20, 840, 756, 81, 457, 36, 149, 16, 355, 8, 16, 147, 5, 4, 120, 44, 16, 41, 37, 110, 50, 4, 39, 316, 1315, 3, 1, 790, 841, 23, 3, 198, 7, 14, 842, 10, 30, 320, 24, 1316, 31, 15, 804, 8, 1, 843, 1317, 477, 459, 16, 121, 58, 501, 56, 127, 1318, 1319, 569, 1, 802, 1320, 2, 16, 41, 3, 1321, 3, 24, 91, 1322, 259, 69, 844, 1323, 48, 6, 172, 83, 845, 152, 127, 1324, 2, 69, 846, 5, 69, 847], [47, 7, 157, 6, 87, 22, 33, 57, 48, 397, 3, 555, 109, 1, 398, 8, 37, 71, 22, 34, 221, 28, 17, 158, 177, 9, 159, 54, 8, 38, 399, 78, 9, 33, 400, 221, 81, 47, 9, 556, 25, 1, 291, 24, 292, 62, 293, 3, 557, 401, 29, 1, 222, 14, 110, 44, 1, 123, 61, 21, 37, 1, 402, 14, 403, 558, 6, 1, 294, 14, 42, 404, 25, 1, 559, 2, 1, 72, 42, 168, 9, 111, 31, 48, 5, 20, 848, 111, 31, 48, 5, 726, 314, 253, 177, 2, 1, 237, 317, 1, 1325, 411, 8, 1, 84, 14, 1326, 1327], [849, 3, 36, 10, 30, 1328, 3, 117, 6, 63, 129, 26, 71, 1329, 2, 349, 21, 36, 66, 168, 20, 96, 22, 2, 1, 843, 1330, 850, 2, 1, 212, 722, 5, 20, 45, 11, 1, 42, 182, 851, 852, 17, 803, 68, 3, 1, 1331, 6, 1, 853, 1332, 2, 181, 37, 17, 1333, 8, 48, 1334, 4, 477, 1335, 40, 854, 410, 146, 40, 1336, 85, 42, 31, 96, 1337, 178, 9, 1338, 4, 313, 1339, 1340, 20, 11, 34, 7, 103, 117, 6, 7, 250, 253, 4, 113, 855, 22, 146, 6], [1, 66, 647, 2, 45, 11, 82, 92, 93, 108, 2, 140, 244, 1, 648, 246, 1, 649, 650, 1, 12, 2, 1, 651, 247, 1, 12, 2, 1, 77, 652, 1, 12, 2, 1, 653, 654, 1, 12, 2, 1, 77, 655, 1, 179, 2, 656, 657, 1, 12, 2, 1, 449, 23, 1, 12, 2, 1, 658, 659, 1, 12, 2, 1, 660, 450, 1, 12, 2, 661, 105, 90, 1, 12, 2, 1, 662, 663, 244, 7, 116, 6, 20, 45, 11, 83, 856, 479, 22, 2, 190, 857, 858, 55, 749, 1341, 69, 155, 73, 428, 1342, 3, 126, 1343, 1344, 1345, 3, 69, 1346, 1347, 32, 507, 362, 46, 65, 9, 51, 20, 11, 10, 83, 26, 4, 416, 260, 363, 3, 9, 34, 10, 30, 131, 5, 148, 3, 52, 24, 204, 4, 13, 26, 135, 24, 508, 8, 859, 107, 103, 860, 25, 52, 20, 11], [40, 1, 223, 20, 861, 6, 9, 31, 3, 52, 6, 71, 22, 27, 421, 1348, 28, 17, 159, 6, 1, 151, 58, 8, 38, 84, 1, 66, 364, 3, 86, 4, 1349, 862, 8, 24, 863, 864, 10, 865, 144, 6, 7, 59, 141, 50, 5, 864, 10, 865, 320, 6, 7, 59, 701, 3, 440, 3, 50, 29, 16, 866, 173, 13, 17, 102, 5, 126, 50, 493, 6, 15, 28, 27, 867, 74, 79, 4, 353, 28, 9, 1350, 52, 144, 71, 452, 31, 11, 1351, 1352, 3, 16, 868], [9, 1353, 6, 130, 61, 47, 7, 114, 457, 6, 149, 7, 509, 5, 869, 9, 32, 870, 5, 9, 871, 8, 24, 41, 29, 9, 73, 1354, 3, 1355, 101, 106, 38, 872, 258, 350, 456, 38, 873, 40, 874, 185, 9, 111, 104, 3, 60, 52, 174, 161, 34, 10, 14, 6, 61, 37, 1356, 52, 78, 7, 28, 845, 9, 41, 3, 41, 5, 510, 20, 11, 20, 11, 15, 31, 1357, 1, 813, 2, 16, 1358, 5, 1359, 1, 838, 2, 4, 1360, 875, 37, 1361, 40, 1, 1362, 1363], [97, 7, 365, 6, 9, 13, 17, 1, 511, 3, 512, 122, 21, 22, 2, 190, 366, 5, 27, 3, 513, 1, 514, 20, 367, 515, 169, 21, 4, 261, 25, 4, 39, 262, 368, 21, 16, 41, 210, 11, 310, 21, 16, 263, 21, 1, 205, 5, 25, 1, 206, 5, 4, 264, 516, 364, 3, 265, 517, 1, 266, 180, 1, 518, 1, 142, 326, 441, 82, 92, 93, 7, 33, 498, 21, 24, 271, 20, 45, 11, 22, 156, 8, 1, 1364, 2, 130, 876, 5, 139, 50, 8, 282, 1365, 25, 4, 39, 1366, 1367, 1368, 1369, 175, 25, 1370, 142, 877], [29, 43, 33, 429, 1, 519, 14, 1371, 686, 74, 412, 878, 5, 1, 687, 2, 20, 1372, 879, 2, 880, 1373, 1374, 1375, 1, 1376, 2, 49, 881, 91, 23, 1377, 247, 2, 595, 882, 5, 883, 55, 1378, 1, 1379, 25, 16, 1380, 520, 5, 257, 40, 22, 2, 54, 3, 1, 64, 25, 4, 884, 41, 37, 14, 570, 25, 885, 1, 12, 2, 1, 446, 77, 330, 82, 92, 93, 43, 58, 734, 842, 3, 277, 1381, 1382, 35, 318, 251, 34, 7, 17, 4, 1383, 1384, 2, 22, 37, 460, 54, 44, 4, 1385, 1386, 220, 87, 886, 94, 1387, 409, 466, 5, 887, 20, 45, 11, 4, 1388, 330, 2, 49, 521], [97, 7, 365, 6, 9, 13, 17, 1, 511, 3, 512, 122, 21, 22, 2, 190, 366, 5, 27, 3, 513, 1, 514, 20, 367, 515, 169, 21, 4, 261, 25, 4, 39, 262, 368, 21, 16, 41, 210, 11, 310, 21, 16, 263, 21, 1, 205, 5, 25, 1, 206, 5, 4, 264, 516, 364, 3, 265, 517, 1, 266, 180, 1, 518, 74, 816, 15, 817, 818, 358, 35, 1, 819, 2, 1, 820, 499, 21, 1, 821, 41, 10, 30, 27, 171, 2, 24, 500, 3, 24, 246, 34, 822, 4, 359, 360, 823, 5, 7, 51, 7, 219, 501, 824, 217, 3, 15, 132, 56, 825, 128, 3, 1, 826, 34, 196, 15, 28, 827, 10, 63, 14, 4, 828, 829, 2, 128, 21, 1, 478, 1, 430, 496, 149, 830, 5, 40, 1, 502, 43, 28, 60, 20, 351, 361, 503, 35, 1, 831, 2, 16, 832, 122, 1, 833], [161, 10, 30, 267, 32, 522, 3, 1389, 35, 48, 888, 49, 521, 10, 30, 267, 32, 522, 3, 596, 4, 80, 3, 1390, 75, 806, 168, 22, 13, 236, 6, 14, 1, 307, 119, 3, 126, 75, 1391, 10, 30, 267, 32, 133, 3, 225, 339, 47, 69, 1392, 73, 1393, 3, 1394, 22, 23, 10, 30, 267, 32, 133, 3, 26, 1395, 25, 4, 1396, 889, 47, 63, 30, 166, 113, 1397, 69, 484, 5, 162, 7, 59, 115, 6, 10, 14, 39, 267, 32, 79, 112, 3, 163, 4, 342, 259, 243, 34, 53, 7, 17, 1398, 21, 1, 732, 523, 2, 36, 22, 341, 1399, 317, 8, 49, 524, 1, 66, 1400, 40, 1, 1401, 3, 1, 1402, 433, 32, 10, 129, 106, 751, 6, 80, 890, 5, 75, 269, 17, 1403, 891, 3, 54, 6, 27, 22, 892, 2, 69, 340, 30, 3, 26, 1404, 6, 172, 17, 87, 39, 435, 580, 32, 893, 1, 1405, 165, 5, 6, 43, 98, 1406, 70, 66, 32, 488, 385, 152, 796, 40, 133], [101, 20, 45, 11, 31, 1, 80, 29, 43, 1407, 4, 42, 1408, 525, 84, 21, 1, 108, 2, 37, 4, 1409, 1410, 33, 57, 590, 81, 7, 59, 39, 166, 479, 3, 176, 9, 22, 94, 56, 338, 894, 3, 37, 7, 365, 6, 9, 138, 895, 4, 338, 1411, 11, 195, 8, 1412, 25, 16, 526, 1413, 21, 16, 1414, 5, 1, 315, 2, 4, 23, 55, 30, 527, 8, 104, 210, 7, 209, 896, 50, 684, 3, 438, 46, 36, 154, 689, 97, 26, 37, 201, 3, 1415, 16, 897, 48, 1416, 5, 183, 553, 3, 692, 8, 21, 1, 1417, 2, 16, 898], [1, 12, 2, 245, 193, 82, 92, 93, 108, 2, 140, 1, 192, 369, 2, 20, 99, 150, 528, 1, 1418, 2, 1419, 1420, 694, 7, 1, 192, 369, 2, 20, 99, 150, 528, 7, 242, 10, 1421, 8, 24, 1422, 6, 10, 14, 4, 899, 5, 900, 156, 1423, 1, 693, 2, 901, 8, 1, 876, 1424, 9, 60, 100, 43, 17, 68, 1425, 21, 56, 1426, 2, 902, 22, 35, 245, 193, 5, 22, 35, 1427, 1428, 48, 70, 1429, 73, 1430, 3, 226], [1, 431, 45, 11, 82, 92, 93, 108, 2, 140, 4, 323, 8, 324, 1, 164, 2, 1, 325, 1, 609, 2, 45, 11, 4, 610, 8, 611, 1, 142, 326, 441, 4, 66, 2, 612, 1, 613, 327, 191, 1, 234, 614, 615, 1, 23, 25, 1, 616, 617, 1, 12, 2, 1, 384, 618, 1, 12, 2, 1, 413, 188, 1, 12, 2, 1, 442, 443, 1, 12, 2, 1, 619, 620, 1, 12, 2, 1, 621, 328, 1, 12, 2, 1, 622, 623, 1, 386, 2, 45, 11, 283, 284, 1, 387, 41, 1, 388, 389, 218, 1, 270, 150, 1, 390, 391, 1, 392, 393, 1, 394, 23, 1, 285, 286, 1, 287, 288, 1, 289, 290, 1, 395, 179, 1, 240, 2, 45, 11, 1, 12, 2, 1, 243, 72, 1, 12, 2, 1, 624, 625, 1, 12, 2, 1, 415, 112, 1, 12, 2, 1, 626, 627, 1, 12, 2, 1, 628, 629, 1, 12, 2, 329, 630, 1, 12, 2, 631, 632, 633, 1, 12, 2, 1, 444, 634, 1, 12, 2, 1, 77, 445, 1, 12, 2, 1, 635, 636, 637, 1, 12, 2, 1, 446, 77, 330, 1, 12, 2, 1, 638, 639, 1, 12, 2, 1, 331, 420, 1, 640, 2, 1, 641, 1, 327, 2, 116, 16, 130, 332, 244, 1, 12, 2, 245, 193, 1, 12, 2, 1, 642, 333, 1, 12, 2, 1, 142, 643, 1, 12, 2, 1, 644, 645, 170, 1, 12, 2, 1, 189, 646, 1, 447, 2, 80, 334, 448, 1, 12, 2, 1, 335, 336, 16, 130, 332, 4, 323, 8, 324, 108, 2, 140, 171, 7, 20, 45, 11, 1, 337, 2, 241, 1, 664, 372, 191, 46, 99, 665, 33, 3, 235, 70, 666, 667, 4, 668, 669, 153, 670, 46, 15, 129, 65, 671, 8, 1, 672, 171, 673, 44, 1, 89, 674, 338, 1, 248, 2, 675, 99, 676, 677, 25, 1, 678, 4, 451, 32, 131, 1, 679, 680, 4, 681, 2, 1, 682, 2, 99, 100, 683, 9, 65, 27, 295, 296, 3, 38, 64, 89, 297, 34, 53, 9, 28, 32, 22, 223, 160, 224, 8, 1, 90, 2, 36, 91, 23, 13, 9, 124, 1, 39, 61, 125, 1, 138, 33, 57, 110, 3, 225, 38, 85, 13, 10, 27, 298, 299, 3, 9, 3, 126, 48, 39, 226, 4, 300, 180, 1, 56, 181, 161, 13, 9, 124, 49, 301, 47, 9, 73, 182, 3, 26, 8, 1, 72, 47, 4, 227, 67, 228, 9, 8, 5, 162, 13, 9, 86, 1, 89, 302, 3, 303, 1, 304, 5, 183, 163, 38, 95, 305, 29, 4, 164, 6, 9, 58, 1, 165, 184, 96, 6, 62, 36, 30, 39, 229], [42, 31, 70, 1431, 1432, 29, 43, 132, 70, 1433, 3, 240, 474, 113, 3, 475, 10, 67, 57, 4, 377, 439, 32, 52, 7, 17, 527, 24, 443, 5, 7, 17, 527, 4, 1434, 1435, 1436, 5, 46, 17, 7, 1437, 369, 31, 11, 1438, 903, 1439, 1440, 33, 31, 6, 10, 14, 106, 886, 1441, 34, 7, 59, 51, 40, 1, 1442, 6, 43, 201, 3, 554, 5, 40, 1, 155, 6, 43, 132, 6, 10, 98, 17, 57, 1443, 1444], [32, 507, 362, 46, 65, 9, 51, 20, 11, 10, 83, 26, 4, 416, 260, 363, 3, 9, 34, 10, 30, 131, 5, 148, 3, 52, 24, 204, 4, 13, 26, 135, 24, 508, 8, 859, 107, 103, 860, 25, 52, 20, 11, 236, 16, 1445, 20, 11, 29, 15, 88, 16, 204, 904, 40, 4, 1446, 1447, 896, 1, 1448, 5, 88, 203, 21, 1, 1449, 464, 905, 5, 21, 1, 1450], [78, 114, 230, 56, 112, 53, 63, 58, 56, 112, 109, 49, 243, 72, 46, 67, 856, 2, 1, 906, 55, 195, 133, 78, 28, 22, 23, 1451, 1452, 3, 86, 907, 407, 143, 1, 203, 68, 40, 46, 14, 1, 1453, 2, 1, 135, 168, 1454, 33, 71, 171, 8, 10, 78, 114, 1, 1455, 908, 63, 909, 62, 167, 59, 1, 331, 23, 1456, 358, 1, 1457, 892, 910, 196, 1458, 7, 184, 6, 7, 350, 60, 152, 1459, 119, 2, 1460, 62, 230, 472, 44, 1, 39, 61, 125, 16, 911, 1, 1461, 1462, 5, 15, 14, 139, 8, 1, 220, 1463, 21, 1, 205, 2, 1, 1464, 25, 4, 1465, 573, 21, 16, 41, 29, 791, 15, 33, 57, 747, 8, 16, 189, 1466, 3, 120, 118, 21, 4, 912, 131, 5, 44, 343, 42, 102], [167, 59, 15, 86, 1, 199, 81, 2, 1, 529, 53, 15, 354, 3, 1467, 10, 167, 28, 15, 27, 65, 10, 63, 67, 4, 1468, 913, 57, 139, 8, 16, 1469, 46, 1470, 1471, 50, 1, 1472, 914, 909, 62, 407, 28, 15, 4, 915, 3, 1, 1473, 1474, 4, 199, 5, 79, 4, 199, 29, 36, 46, 30, 16, 95, 523, 29, 3, 1, 202, 37, 15, 354, 1, 269, 3, 895, 3, 1, 529, 1475, 15, 731, 6, 10, 14, 4, 1476, 1477, 916, 43, 33, 1, 695, 2, 4, 917, 1478, 3, 488, 6, 197, 29, 43, 1479, 118, 3, 475, 5, 7, 322, 6, 1, 846, 14, 4, 798, 22, 3, 903, 1480, 29, 42, 29, 3, 217, 29, 43, 1481, 3, 70, 1482, 399, 2, 1, 918, 37, 33, 1483, 35, 1, 919, 920, 921, 21, 1, 811, 61, 5, 1, 1484, 74, 37, 15, 33, 1485, 133], [42, 144, 46, 2, 6, 103, 9, 60, 152, 1486, 21, 1, 66, 42, 42, 7, 103, 1487, 21, 10, 70, 80, 98, 17, 922, 75, 128, 207, 98, 76, 27, 168, 44, 1, 22, 374, 76, 13, 163, 4, 923, 44, 1, 194, 5, 44, 1, 64, 49, 421, 1488, 22, 44, 1, 506, 345, 185, 144, 76, 98, 17, 57, 4, 924, 147], [143, 7, 27, 235, 9, 78, 797, 5, 1489, 76, 14, 13, 76, 27, 17, 110, 49, 1490, 1491, 30, 10, 27, 4, 1492, 6, 76, 14, 27, 44, 24, 530, 40, 46, 7, 17, 178, 2, 1, 80, 76, 1493, 452, 3, 26, 44, 4, 39, 316, 530, 3, 38, 1494, 31, 11, 1495, 7, 1496, 1, 925, 4, 147, 8, 1497, 122, 69, 1498, 5, 476, 8, 1499, 1500, 4, 1501, 2, 259, 5, 259, 56, 1502, 2, 1503, 1504, 5, 29, 166, 1505, 29, 7, 28, 926, 455, 581, 1506, 3, 115, 608, 2, 259, 4, 1507, 64, 717, 8, 1, 1508, 8, 198, 7, 14, 27, 8, 1, 1509, 1510, 34, 408, 1511, 7, 14, 1512, 3, 849, 3], [34, 36, 107, 11, 1513, 185, 8, 66, 10, 59, 68, 347, 10, 13, 927, 26, 29, 42, 6, 9, 59, 1514, 38, 928, 25, 1, 736, 5, 1515, 2, 1, 135, 5, 20, 11, 929, 10, 20, 11, 348, 929, 930, 63, 30, 3, 117], [34, 167, 13, 9, 27, 228, 52, 1516, 9, 168, 63, 14, 8, 1517, 71, 931, 129, 9, 176, 24, 382, 100, 65, 9, 236, 6, 7, 17, 71, 932, 32, 38, 1518, 1519, 28, 7, 322, 6, 38, 1520, 309, 13, 1521, 4, 189, 23, 55, 321, 1522, 33, 71, 904, 2, 933, 94, 934, 35, 325, 1523, 7, 28, 370, 9, 160, 10, 122, 122, 36, 524, 100, 36, 524, 7, 115, 16, 526, 1524, 118, 21, 1, 1525, 5, 15, 887, 4, 282, 935, 2, 1526, 29, 7, 1527, 1, 333, 21, 1, 696], [42, 7, 232, 3, 60, 1, 23, 55, 491, 174, 930, 15, 83, 352, 169, 31, 11, 1528, 1, 447, 2, 80, 334, 448, 82, 92, 93, 34, 167, 1529, 417, 20, 45, 11, 1530, 1531, 35, 24, 1532], [7, 14, 936, 6, 937, 938, 14, 1, 135, 6, 32, 1, 362, 2, 371, 5, 25, 1, 426, 927, 6, 53, 1, 64, 850, 2, 16, 531, 58, 62, 939, 15, 13, 26, 1, 1533, 1534, 2, 69, 1535, 1536, 15, 33, 379, 1, 335, 336, 940, 21, 133, 1537, 56, 2, 133, 81, 2, 69, 1538, 5, 357, 16, 216, 941, 1, 22, 1539, 465, 198, 7, 17, 250, 469, 94, 55, 67, 250, 469, 52, 7, 83, 17, 1540, 21, 24, 1541, 735, 2, 1542, 1543, 34, 111, 17, 7, 1544, 35, 10, 113, 146, 21, 6, 942, 220, 8, 1545, 47, 32, 56, 483, 15, 1546, 21, 1547, 1548, 5, 1549, 29, 1550, 29, 53, 71, 1551, 191, 58, 1552, 32, 16, 690]]\n",
      "1733\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tok = Tokenizer() #instansiate tokenizer\n",
    "tok.fit_on_texts(x + y) #ID for tokens \n",
    "\n",
    "\n",
    "\n",
    "encoder_input_seq = tok.texts_to_sequences(x) #Fit Ids each sequence\n",
    "decoder_input_seq = tok.texts_to_sequences(y)\n",
    "print(encoder_input_seq)\n",
    "vocab_size = len(tok.word_index)+1 #add 1 to offset indicie syntax\n",
    "\n",
    "max_encoder_seq = max(len(seq) for seq in encoder_input_seq)\n",
    "max_decoder_seq = max(len(seq) for seq in decoder_input_seq) #tokens in target\n",
    "\n",
    "encoder_input_seq = pad_sequences(encoder_input_seq, maxlen=max_encoder_seq, padding='post') #padding at the end of sequence\n",
    "decoder_input_seq = pad_sequences(decoder_input_seq, maxlen=max_decoder_seq, padding='post')\n",
    "\n",
    "encoder_inputs = Input(shape=(max_encoder_seq,)) #input shape is (None(variable batch size), max_encoder_seq)\n",
    "encoder_embeddings = Embedding(input_dim=vocab_size, output_dim=64)(encoder_inputs)#in: vocab size[], #out: 64[]\n",
    "encoder_lstm = LSTM(64, return_state=True) #return final state\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings) #final state and long term memory\n",
    "encoder_states = [state_h, state_c] #ready to pass info from short term and long term memory into decoder \n",
    "\n",
    "print(vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3197903d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 21), dtype=float32, sparse=False, ragged=False, name=keras_tensor_64>\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = Input(shape=(max_decoder_seq,))\n",
    "decoder_embedding = Embedding(input_dim=vocab_size, output_dim=64,)(decoder_inputs)\n",
    "decoder_lstm = LSTM(64, return_state=True, return_sequences=True)#each sequence\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_embedding, initial_state=encoder_states) #Context vector = initial state \n",
    "\n",
    "decoder_dense = Dense(vocab_size, activation='softmax') \n",
    "decoder_outputs = decoder_dense(decoder_outputs) #probability distribution \n",
    "\n",
    "print(decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bcc0470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 7.0659\n",
      "Epoch 2/10\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 5.7594\n",
      "Epoch 3/10\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 5.3609\n",
      "Epoch 4/10\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 5.1166\n",
      "Epoch 5/10\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 4.9261\n",
      "Epoch 6/10\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 4.7981\n",
      "Epoch 7/10\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 4.6949\n",
      "Epoch 8/10\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 4.8298\n",
      "Epoch 9/10\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 4.8559\n",
      "Epoch 10/10\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 4.5550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x316542950>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "decoder_target_seq = np.zeros_like(decoder_input_seq)\n",
    "decoder_target_seq[:, :-1] = decoder_input_seq[:, 1:] #Shift tokens for sos \n",
    "model.fit([encoder_input_seq, decoder_input_seq],\n",
    "          np.expand_dims(decoder_target_seq, axis=-1),\n",
    "          batch_size=1,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1043d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input sequence to get the context vectors\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Initialize the target sequence with the start token\n",
    "    start_token = tok.word_index[\"sos\"]  \n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = start_token\n",
    "\n",
    "    # Placeholder for the decoded sentence\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # Loop for maximum sequence length\n",
    "    for _ in range(max_decoder_seq):\n",
    "        # Predict the next word\n",
    "        \n",
    "        output_tokens, h, c  = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # Get the index of the most likely word\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tok.index_word.get(sampled_token_index, \"\")\n",
    "\n",
    "        # Append the word to the decoded sentence\n",
    "        decoded_sentence += \" \" + sampled_word\n",
    "\n",
    "        # Exit if the end token is predicted\n",
    "        if sampled_word == \"eos\" or sampled_word == \"\":\n",
    "            break\n",
    "\n",
    "        # Update the target sequence with the sampled word\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        \n",
    "        # Update the states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23c9aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code\n",
    "\n",
    "#Set Up the Inference Models\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Inputs for inference decoder\n",
    "decoder_state_input_h = Input(shape=(64,))\n",
    "decoder_state_input_c = Input(shape=(64,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Decoder embedding\n",
    "decoder_inputs_single = Input(shape=(1,))  # Decoder only processes one word at a time\n",
    "decoder_embedding_inf = Embedding(input_dim=vocab_size, output_dim=64)(decoder_inputs_single)\n",
    "\n",
    "# LSTM for inference\n",
    "decoder_lstm_inf = LSTM(64, return_sequences=True, return_state=True)\n",
    "decoder_outputs_inf, state_h_inf, state_c_inf = decoder_lstm_inf(\n",
    "    decoder_embedding_inf, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states_inf = [state_h_inf, state_c_inf]\n",
    "\n",
    "# Dense layer for predictions\n",
    "decoder_outputs_inf = decoder_dense(decoder_outputs_inf)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single] + decoder_states_inputs,\n",
    "    [decoder_outputs_inf] + decoder_states_inf\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48d3a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "WARNING:tensorflow:5 out of the last 25 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x126ec99e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Predicted Summary:  heard heard heard heard heard heard heard heard heard heard heard heard heard heard heard heard heard heard heard heard heard\n",
      "[[157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157]]\n",
      "[<KerasTensor shape=(None, 64), dtype=float32, sparse=False, ragged=False, name=keras_tensor_75>, <KerasTensor shape=(None, 64), dtype=float32, sparse=False, ragged=False, name=keras_tensor_76>]\n"
     ]
    }
   ],
   "source": [
    "# Run this code\n",
    "# Prepare the input sequence\n",
    "input_seq = pad_sequences(\n",
    "    tok.texts_to_sequences([x[1]]), maxlen=max_encoder_seq, padding=\"post\"\n",
    ")\n",
    "\n",
    "# Decode the sequence\n",
    "predicted_summary = decode_sequence(input_seq)\n",
    "print(\"Predicted Summary:\", predicted_summary)\n",
    "\n",
    "print(tok.texts_to_sequences([predicted_summary]))\n",
    "\n",
    "\n",
    "print(decoder_states_inf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "state_h: [[ 0.8624176   0.28371805  0.9409557   0.77715236  0.91678274  0.95000637\n",
      "   0.86485267  0.7427584  -0.08785291 -0.32784805  0.3209581  -0.08945001\n",
      "   0.7184214   0.7647631   0.8590778   0.80216503  0.82303905  0.9006943\n",
      "   0.90912217  0.86652553 -0.03168657  0.960764    0.94392204  0.9045529\n",
      "   0.8744961   0.5007596   0.940282    0.879897    0.8658937   0.8993378\n",
      "   0.82642436  0.83879924  0.7331028   0.87572485  0.84529865  0.5945258\n",
      "   0.820365    0.80582714 -0.6080258   0.62386817  0.7636423   0.93163514\n",
      "   0.8206198   0.7858787   0.98378295  0.8195456   0.7912837   0.5485241\n",
      "   0.87783873  0.98302776  0.3015652   0.87503     0.8544742   0.68554723\n",
      "   0.9284036   0.43899137  0.73533213  0.76753354  0.63997144  0.5833682\n",
      "  -0.06424434 -0.3064934  -0.13768679  0.8681411 ]]\n",
      "state_c: [[  5.3686256    1.5241761   10.688972     8.109865    10.804737\n",
      "    6.1196046    7.6669064    4.9112334   -0.19952646  -0.46976086\n",
      "    4.676361    -0.11249101   4.509251     6.463451     3.1912198\n",
      "    5.8859816    2.1632736    5.292608     6.444114     4.3230534\n",
      "   -0.10971513   5.2277365    6.78471     10.416911    12.655635\n",
      "    4.884884    11.428318     6.3487864   10.288439     7.9548583\n",
      "    9.502524    10.944349    17.815462    10.870018     5.0390725\n",
      "    7.355817     7.929812     8.482295   -25.26189      6.87606\n",
      "    2.4682326    6.6577806    4.4273386    7.736468     9.798433\n",
      "    8.57535      2.160237     3.3014138    4.1850286    8.132546\n",
      "    1.6344218   10.489226     8.56686      4.151524     5.7532883\n",
      "   11.255537     5.7302094    8.481867     4.52039      5.1786675\n",
      "   -0.16756815  -2.444917    -0.24156511   4.7522697 ]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
